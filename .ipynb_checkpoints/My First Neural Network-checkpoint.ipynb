{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "c2403955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "3b9bcfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the neural network.\n",
    "        This sets up the initial synaptic weights and seeds the random number generator\n",
    "        for reproducibility.\n",
    "        \"\"\"\n",
    "        # Seed the random number generator to ensure consistent results\n",
    "        np.random.seed(1)\n",
    "\n",
    "        # Initialize synaptic weights randomly with values in the range [-1, 1]\n",
    "        # for a 2x1 matrix (2 input features, 1 output neuron)\n",
    "        self.synaptic_weights = np.random.randn(2, 1) * np.sqrt(2. / 2)\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        \"\"\"\n",
    "        The sigmoid activation function maps any value into the range [0, 1].\n",
    "        It is used to introduce non-linearity into the model.\n",
    "        \"\"\"\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def sigmoid_derivative(self, x):\n",
    "        \"\"\"\n",
    "        The derivative of the sigmoid function, used to calculate the gradient\n",
    "        during the weight adjustment phase (backpropagation).\n",
    "        \"\"\"\n",
    "        return x * (1 - x)\n",
    "\n",
    "    def train(self, training_inputs, training_outputs, validation_inputs, validation_outputs, training_iterations):\n",
    "        \"\"\"\n",
    "        Train the neural network by repeatedly adjusting the synaptic weights\n",
    "        to minimize the error in the output.\n",
    "        \n",
    "        Parameters:\n",
    "        - training_inputs: The input data used to train the model.\n",
    "        - training_outputs: The expected output for the input data.\n",
    "        - training_iterations: Number of times to iterate over the training process.\n",
    "        \"\"\"\n",
    "        for iteration in range(training_iterations):\n",
    "            # Pass the training inputs through the neural network\n",
    "            output = self.think(training_inputs)\n",
    "\n",
    "            # Calculate the error as the difference between expected and actual outputs\n",
    "            error = training_outputs - output\n",
    "\n",
    "            # Calculate adjustments to weights using the error, the inputs, and the sigmoid derivative\n",
    "            adjustments = np.dot(training_inputs.T, error * self.sigmoid_derivative(output))\n",
    "\n",
    "            # Update synaptic weights with the adjustments\n",
    "            self.synaptic_weights += adjustments\n",
    "            \n",
    "            if iteration % 10000 == 0:\n",
    "                print(f\"Iteration {iteration},\\nTraining Error: {np.mean(np.abs(error))}\")\n",
    "                # Validate the model's performance on the validation set\n",
    "                validation_output = self.think(validation_inputs)\n",
    "                validation_error = validation_outputs - validation_output\n",
    "                print(f\"Validation Error: {np.mean(np.abs(validation_error))}\")\n",
    "                print('-------------------------------------------------------')\n",
    "\n",
    "    def think(self, inputs):\n",
    "        \"\"\"\n",
    "        Pass inputs through the neural network to calculate the output.\n",
    "        \n",
    "        Parameters:\n",
    "        - inputs: The input data to process.\n",
    "        \n",
    "        Returns:\n",
    "        - The calculated output after applying weights and the sigmoid function.\n",
    "        \"\"\"\n",
    "        # Ensure the inputs are of float type to avoid issues during calculations\n",
    "        inputs = inputs.astype(float)\n",
    "        \n",
    "        # Perform a dot product of the inputs and weights, then apply the sigmoid function\n",
    "        output = self.sigmoid(np.dot(inputs, self.synaptic_weights))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "d633a65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main execution: Training and testing the neural network\n",
    "if __name__ == \"__main__\":    \n",
    "    neural_network = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "a0afaba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random starting synaptic weights: \n",
      "[[ 1.62434536]\n",
      " [-0.61175641]]\n"
     ]
    }
   ],
   "source": [
    "    # Display the initial random synaptic weights\n",
    "    print(\"Random starting synaptic weights: \")\n",
    "    print(neural_network.synaptic_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b20df972",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Definition the training dataset:\n",
    "    # Each row is an example with 2 inputs, and the corresponding expected output is in `training_outputs` block under\n",
    "    training_inputs = np.array([[0, 0],\n",
    "                                [0, 1],\n",
    "                                [1, 0],\n",
    "                                [1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "b18c7181",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # The expected outputs for the training dataset (column vector)\n",
    "    # Outputs are based on a custom rule (sum of inputs is odd -> output 1)\n",
    "    training_outputs = np.array([[0,1,0,1]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "4328ce2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Split the data (80% train, 20% validate)\n",
    "    train_size = int(0.8 * len(training_inputs))\n",
    "    val_size = len(training_inputs) - train_size\n",
    "\n",
    "    # Create training and validation datasets\n",
    "    train_inputs, val_inputs = training_inputs[:train_size], training_inputs[train_size:]\n",
    "    train_outputs, val_outputs = training_outputs[:train_size], training_outputs[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "796cdeb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0,\n",
      "Training Error: 0.5625520978699162\n",
      "Validation Error: 0.24054312187155025\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "    # Train the neural network with the training data for 50,000 iterations\n",
    "    neural_network.train(training_inputs, training_outputs, val_inputs, val_outputs, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "9ffb1937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synaptic weights after training: \n",
      "[[-4.36633509]\n",
      " [ 8.93927325]]\n"
     ]
    }
   ],
   "source": [
    "    # Display the synaptic weights after training\n",
    "    print(\"Synaptic weights after training: \")\n",
    "    print(neural_network.synaptic_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "0022b36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input 1: 1\n",
      "Input 2: 1\n"
     ]
    }
   ],
   "source": [
    "    # Take new inputs from the user for testing\n",
    "    A = int(input(\"Input 1: \"))  # First input feature\n",
    "    B = int(input(\"Input 2: \"))  # Second input feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "5b7857e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New input data (binary) = 11\n",
      "New input data (decimal) = 3\n"
     ]
    }
   ],
   "source": [
    "    # Print the binary input values\n",
    "    print(f\"New input data (binary) = {A}{B}\")\n",
    "\n",
    "    # Convert binary input to decimal\n",
    "    decimal_input = A * 2 + B * 1  # Corresponding to 2^1, 2^0\n",
    "    print(f\"New input data (decimal) = {decimal_input}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "3c38fca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output data: \n",
      "[0.989778]\n"
     ]
    }
   ],
   "source": [
    "    # Predict the output for the new inputs\n",
    "    print(\"Output data: \")\n",
    "    print(neural_network.think(np.array([A, B])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
